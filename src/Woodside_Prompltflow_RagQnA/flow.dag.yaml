id: bring_your_own_data_qna
name: Bring Your Own Data QnA
inputs:
  question:
    type: string
    default: what is The doctrine of precedent?
    is_chat_input: false
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
nodes:
- name: lookup
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.common_index_lookup.search
  inputs:
    mlindex_content: >
      embeddings:
        kind: none
        schema_version: '2'
      index:
        api_version: '2020-08-01'
        connection:
          id: /subscriptions/20dd0807-4bab-40e8-a83e-75a1f4548c29/resourceGroups/LAB3GPTDEVRG01/providers/Microsoft.MachineLearningServices/workspaces/labmltest02/connections/azure_open_ai_search
        connection_type: workspace_connection
        endpoint: https://lab3aisearch.search.windows.net
        engine: azure-sdk
        index: courtinfo-index
        field_mapping:
          content: content
          embedding: contentVector
          metadata: meta_json_string
        kind: acs
        semantic_configuration_name: null
    queries: ${inputs.question}
    query_type: Keyword
    top_k: 2
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${lookup.output}
  use_variants: false
- name: Prompt_variants
  use_variants: true
- name: answer_the_question_with_context
  type: llm
  source:
    type: code
    path: answer_the_question_with_context.jinja2
  inputs:
    deployment_name: gpt-4o
    temperature: 0
    top_p: 1
    max_tokens: 1000
    response_format:
      type: text
    presence_penalty: 0
    frequency_penalty: 0
    prompt_text: ${Prompt_variants.output}
  provider: AzureOpenAI
  connection: azure_open_ai_connection
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
node_variants:
  Prompt_variants:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${inputs.question}
      variant_1:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__variant_1.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${inputs.question}
      variant_2:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__variant_2.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${inputs.question}
environment:
  python_requirements_txt: requirements.txt
